---
title: "P8105_hw6"
author: "Jingyu Xu"
date: "2018/11/22"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

#Problem 1 
```{r}
library(tidyverse)
set.seed(1)
homcide = read_csv( file = "./data/homicide-data.csv")
```

###data cleaning
A code chunk below is used to clean the data:
1)Create a city_state variable (e.g. “Baltimore, MD”) and a binary variable indicating whether the homicide is solved. 
2)Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. omit Tulsa, AL – this is a data entry mistake.
3)Modifiy victim_race to have categories white and non-white, with white as the reference category. Make sure that victim_age is numeric.
```{r}
homcide = homcide %>%
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, ",", state)) %>%
  subset(!city_state %in% c("Dallas,TX","Phoenix,AZ","Kansas City,MO","Tulsa,AL")) %>%
  mutate(victim_race = ifelse(victim_race != "White", "non-white", "white")) %>%
  mutate(victim_age = as.numeric(victim_age), victim_race = fct_relevel(victim_race, "white"))
```


###Baltimore Division
For the city of Baltimore, MD, a code chunk is used to utilize the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors.  

```{r}
Baltimore = filter(homcide, city_state == "Baltimore,MD") %>%
mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>%
select(resolved, victim_age, victim_race, victim_sex)

fit_logistic = 
  Baltimore %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>%
  broom::tidy(conf.int = TRUE) %>%
  mutate(OR = exp(estimate), conf.low = exp(conf.low), conf.high = exp(conf.high))     %>%
  filter(term == "victim_racenon-white") %>%
  select(term,OR, conf.low,conf.high)

knitr::kable(fit_logistic)
```

Thus, keeping all other variables fixed, the estimate of the adjusted odds ratio for solving homicides comparing non-white victims to white victims is 0.440608. And we are 95% confident that the estimate fall into (0.3121625, 0.6196693)

###glm for all the cities in the dataset
Now, a code chunk is used to run glm for each of the cities in the dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. 
```{r}
##exclude more city with unknown victim-race
homcide1 = homcide %>%
  filter(victim_race != "unknown") %>%
  mutate(resolved = as.numeric(disposition == "Closed by arrest"))

nest_lm_res =
  homcide1 %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
  models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>%
  mutate(OR = exp(estimate), conf.low = exp(estimate - qnorm(0.975)*std.error), conf.high = exp(estimate + qnorm(0.975)*std.error)) %>%
  filter(term == "victim_racenon-white") %>%
  select(city_state,term,OR, conf.low,conf.high)
```

Then, a code chunk is used to create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.
```{r}
nest_lm_res %>%
mutate(city_state = fct_reorder(city_state, OR)) %>%
ggplot(aes(x = city_state, y = OR)) +
geom_point() +
geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
geom_hline(yintercept = 1.0, color = "red") +
theme(axis.text.x =  element_text(angle = 80)) +
labs(
title = "the estimated OR and CIs for solving homcide comparing non-white to white victims across the U.S.",
x = "city",
y = "estimates and CIs"
)
```

In the graph, I use odds ratio = 1.0 as a cut-off line. We can observe that there are only three cities (Durham, NC; Birmingham, AL; Tampa, FL) which have the estimated odds ratio over 1.0, indicating that the odds of solving non-white victims is larger than the odds of solving white victims. Also, we can observe that Boston has the least odds ratio.

#Problem 2
###data cleaning
Firstly, a code chunk is used to load and clean the data for regression analysis:
1)convert some variables to factor, based on the meaning in the real application.
2)use summary function to see whether there are "unknown" observation.
3)use sum(is.na()) to check whether there are missing data.
```{r}
birthweight = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace), 
    malform = as.factor(malform), 
    mrace = as.factor(mrace))
# check for unknown observation
summary(birthweight)
#check for missing data
sum(is.na(birthweight))
```

We can see that there is no missing data in the dataset.


###construct own regression model
I use stepwise regression to construct the multiple linear regression models for birthweight.
```{r}
mlr = lm(bwt ~ ., data = birthweight)
step(mlr, direction = 'both')
```

After the stepwise procedure,  we get a optimal(not globle) model based on the selection rule.(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken). So I Save the output of final glm as an R object
```{r}
mlr_own = lm( bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight)
```

### show a plot of model residuals against fitted values

```{r}
library(modelr)
birthweight %>% 
  add_predictions(mlr_own) %>% 
  add_residuals(mlr_own) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Model Residuals against Fitted Values",
        x = "Fitted values",
        y = "Residuals of model")
```

From the graph, We observe that when the predictions are bewteen 2000 and 4000, the residuals are almost evenly settled around zero. However, when the fitted values are in the other intervals, the trend of distribution is quite different from that of [2000,4000] and is not evenly distributed. So we can conclude that this model doesn't fit when the predicted value is less than 2000 or larger than 4000.

### compare own models to two other models
Now, compare my own model to two others:
1)I denote the own model as model_own
2)Construct one using length at birth and gestational age as predictors (main effects only) and denote it as model_A
3)Construct One using head circumference, length, sex, and all interactions (including the three-way interaction) between these and denote it as model_B

```{r}
#construct cross-validation 
cv_df = 
  crossv_mc(birthweight, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(model_own = map(train, ~lm(bwt ~  babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
         model_A = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_B = map(train, ~lm(bwt ~ (bhead + blength + babysex)^4, data = .x)),
         rmse_own = map2_dbl(model_own, test, ~rmse(model = .x, data = .y)),
         rmse_A = map2_dbl(model_A, test, ~rmse(model = .x, data = .y)),
         rmse_B = map2_dbl(model_B, test, ~rmse(model = .x, data = .y)))
```

